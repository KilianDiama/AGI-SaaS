from noyau_core import BasePlugin, Context, Meta
import logging

logger = logging.getLogger("plugin.coherence_guardian")

class PluginCoherenceGuardian(BasePlugin):
    meta = Meta(
        name="plugin_coherence_guardian",
        version="1.0",
        priority=3.9,  # Juste avant la fusion et apr√®s les r√©ponses LLM
        author="Toi & GPT"
    )

    async def run(self, ctx: Context) -> Context:
        reponse = ctx.get("llm_response", "")
        contexte = ctx.get("context_injection", "")
        objectif = ctx.get("objectif", {}).get("but", "")
        intention = ctx.get("intention", "")

        alertes = []

        if not reponse.strip():
            alertes.append("‚ùå Aucune r√©ponse g√©n√©r√©e.")

        if objectif and objectif.lower() not in reponse.lower():
            alertes.append("‚ö†Ô∏è R√©ponse peut-√™tre non align√©e avec l‚Äôobjectif.")

        if intention and intention.lower() not in reponse.lower():
            alertes.append("‚ö†Ô∏è L‚Äôintention de l‚Äôutilisateur ne semble pas prise en compte.")

        if contexte and any(
            mot.lower() not in reponse.lower() for mot in contexte.split()[:5]
        ):
            alertes.append("üîÑ La r√©ponse semble ignorer le contexte inject√©.")

        if alertes:
            ctx["coherence_alertes"] = "\n".join(alertes)
            ctx.setdefault("plugins_log", []).append("PluginCoherenceGuardian : incoh√©rences d√©tect√©es.")
            logger.warning("[CoherenceGuardian] Probl√®mes d√©tect√©s :\n" + "\n".join(alertes))
        else:
            ctx.setdefault("plugins_log", []).append("PluginCoherenceGuardian : r√©ponse valid√©e.")
            logger.info("[CoherenceGuardian] R√©ponse logique et coh√©rente.")

        return ctx
