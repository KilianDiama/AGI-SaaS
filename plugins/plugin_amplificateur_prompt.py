from noyau_core import BasePlugin, Context, Meta
import logging

logger = logging.getLogger("plugin.amplificateur_prompt")

class PluginAmplificateurPrompt(BasePlugin):
    meta = Meta(
        name="plugin_amplificateur_prompt",
        version="1.0",
        priority=4.5,
        author="Toi & GPT"
    )

    async def run(self, ctx: Context) -> Context:
        prompt_brut = ctx.get("llm_prompt", "")
        modele = ctx.get("llm_model", "llm")
        intention = ctx.get("intention", "")
        objectif = ctx.get("objectif", {}).get("but", "")
        resume = ctx.get("memoire_contextuelle", "")

        # Enrichissement du prompt de mani√®re cibl√©e
        amplifications = []

        if "r√©√©cris" in prompt_brut or "am√©liore" in prompt_brut:
            amplifications.append("‚úÖ Am√©lioration du style activ√©e.")
        if resume and len(resume) > 30:
            amplifications.append("üß† R√©sum√© contextuel inject√© pour plus de coh√©rence.")
            prompt_brut = f"[R√©sum√© : {resume}]\n\n{prompt_brut}"

        if intention.lower() in ["cr√©atif", "histoire", "sc√©nario"]:
            prompt_brut = "Tu es un assistant cr√©atif et inspirant.\n\n" + prompt_brut
        elif intention.lower() in ["analyse", "logique", "synth√®se"]:
            prompt_brut = "Tu es un assistant rigoureux et m√©thodique.\n\n" + prompt_brut

        if modele == "mistral":
            prompt_brut = prompt_brut.replace("R√©√©cris", "R√©√©cris clairement pour Mistral :")
        elif modele == "llama3":
            prompt_brut += "\n\nUtilise un style fluide et structur√©."

        ctx["llm_prompt"] = prompt_brut
        ctx.setdefault("plugins_log", []).append("PluginAmplificateurPrompt : prompt enrichi.")
        logger.info(f"[amplificateur_prompt] Prompt enrichi avec : {amplifications}")

        return ctx
