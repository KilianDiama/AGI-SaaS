import logging
from noyau_core import BasePlugin, Context, Meta

logger = logging.getLogger("plugin.ethique_guardian")

class PluginEthiqueGuardian(BasePlugin):
    meta = Meta(
        name="plugin_ethique_guardian",
        version="1.0",
        priority=4.3,  # Apr√®s auto-critique, avant finalisation
        author="Toi & GPT"
    )

    async def run(self, ctx: Context) -> Context:
        response = ctx.get("response", "").strip()
        plugins_log = ctx.setdefault("plugins_log", [])
        flags = []

        if not response:
            plugins_log.append("plugin_ethique_guardian : pas de r√©ponse √† √©valuer")
            return ctx

        # V√©rifications simples
        if any(word in response.lower() for word in ["suicide", "viol", "meurtre"]):
            flags.append("üö® Sujet sensible d√©tect√©")

        if "religion" in response.lower() or "dieu" in response.lower():
            flags.append("‚ö†Ô∏è Contenu religieux d√©tect√©")

        if any(w in response.lower() for w in ["idiot", "d√©bile", "sale"]):
            flags.append("‚ùå Langage inappropri√© ou offensant")

        if "d√©sol√©" in response.lower() and "pas r√©pondre" in response.lower():
            flags.append("üîé R√©ponse vague ou d'√©vitement")

        # Action : injecter les alertes ou modifier le flux
        if flags:
            ctx["ethique_alertes"] = flags
            plugins_log.append(f"plugin_ethique_guardian : alertes = {len(flags)}")
            logger.warning(f"[ethique] Alerte(s) d√©tect√©e(s) : {flags}")
            # Optionnel : bloquer la r√©ponse
            # ctx["response"] = "[‚ö†Ô∏è R√©ponse bloqu√©e pour raisons √©thiques]"
        else:
            plugins_log.append("plugin_ethique_guardian : OK")

        return ctx
