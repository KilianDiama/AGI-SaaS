# plugins/plugin_feedback_iteratif.py

from noyau_core import BasePlugin, Context, Meta
import logging

logger = logging.getLogger("plugin.feedback_iteratif")

class PluginFeedbackIteratif(BasePlugin):
    meta = Meta(
        name="plugin_feedback_iteratif",
        version="1.0",
        priority=3.5,  # AprÃ¨s rÃ©ponse votÃ©e, avant envoi final
        author="Toi & GPT"
    )

    async def run(self, ctx: Context) -> Context:
        response = ctx.get("llm_response_votÃ©e") or ctx.get("llm_response", "")
        if not response.strip():
            ctx.setdefault("plugins_log", []).append("PluginFeedbackIteratif : rÃ©ponse vide, rien Ã  amÃ©liorer.")
            return ctx

        # CrÃ©e une invite d'auto-rÃ©vision
        prompt = (
            "AmÃ©liore cette rÃ©ponse en termes de clartÃ©, structure, fluiditÃ© et humanitÃ©. "
            "Corrige si besoin, mais conserve le sens original.\n\n"
            "---\n"
            f"{response.strip()}\n"
            "---"
        )

        # Simulation d'une amÃ©lioration (Ã  connecter Ã  un LLM local si besoin)
        improved = await self.fake_llm_refine(prompt)

        ctx["llm_response"] = improved
        ctx.setdefault("plugins_log", []).append("PluginFeedbackIteratif : rÃ©ponse amÃ©liorÃ©e par itÃ©ration.")
        logger.info(f"[feedback_iteratif] RÃ©ponse finale amÃ©liorÃ©e injectÃ©e.")

        return ctx

    async def fake_llm_refine(self, prompt: str) -> str:
        # ğŸ‘‰ Ã€ remplacer par un vrai appel LLM si disponible
        return prompt.replace("---", "").replace("AmÃ©liore cette rÃ©ponse", "[AmÃ©lioration automatique]")

