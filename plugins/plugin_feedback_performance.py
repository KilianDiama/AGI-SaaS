"""
Plugin : feedback_performance
RÃ´le : Ã‰valuer la pertinence, la clartÃ© et la cohÃ©rence d'une rÃ©ponse produite
PrioritÃ© : 5 (aprÃ¨s la gÃ©nÃ©ration de rÃ©ponse)
Auteur : GPT pour AGI_X
"""

from noyau_core import BasePlugin, Context, Meta
import logging

logger = logging.getLogger("plugin.feedback_performance")

class FeedbackPerformancePlugin(BasePlugin):
    meta = Meta(
        name="feedback_performance",
        priority=5,
        version="1.0",
        author="GPT"
    )

    async def run(self, ctx: Context) -> Context:
        plugins_log = ctx.setdefault("plugins_log", [])
        response = ctx.get("llm_response", "")

        if not response.strip():
            ctx["feedback_performance"] = "ğŸ”´ RÃ©ponse vide ou absente."
            plugins_log.append("FeedbackPerformancePlugin : rÃ©ponse vide dÃ©tectÃ©e")
            return ctx

        feedback = []

        # Ã‰valuation basique
        if len(response) < 30:
            feedback.append("ğŸŸ¡ RÃ©ponse trÃ¨s courte â€“ pourrait manquer de profondeur.")
        if "je ne sais pas" in response.lower():
            feedback.append("ğŸ”´ Contenu non informatif dÃ©tectÃ©.")
        if response.count("\n") > 10:
            feedback.append("ğŸŸ¡ RÃ©ponse potentiellement trop longue ou verbeuse.")
        if response.lower().startswith("oui") or response.lower().startswith("non"):
            feedback.append("ğŸŸ  RÃ©ponse binaire â€“ vÃ©rifier si justifiÃ©e.")

        if not feedback:
            feedback.append("ğŸŸ¢ RÃ©ponse apparemment claire et pertinente.")

        ctx["feedback_performance"] = "\n".join(feedback)
        plugins_log.append("FeedbackPerformancePlugin : feedback gÃ©nÃ©rÃ©")
        logger.info("[feedback_performance] Feedback d'auto-Ã©valuation produit")

        return ctx
